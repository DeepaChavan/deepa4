{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#rnn code for sentiment analysis\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)\n",
        "x_train = pad_sequences(x_train, maxlen=80)\n",
        "x_test  = pad_sequences(x_test, maxlen=80)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=80))\n",
        "model.add(SimpleRNN(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=32)\n",
        "\n",
        "\n",
        "pred = (model.predict(x_test) > 0.5).astype(int)\n",
        "\n",
        "\n",
        "from random import randint\n",
        "arr_ind = randint(0, len(x_test)-1)\n",
        "\n",
        "\n",
        "index = imdb.get_word_index()\n",
        "reverse_index = {value: key for key, value in index.items()}\n",
        "decoded = \" \".join([reverse_index.get(i - 3, \"#\") for i in x_test[arr_ind]])\n",
        "\n",
        "\n",
        "label = \"Positive\" if pred[arr_ind][0] == 1 else \"Negative\"\n",
        "\n",
        "print(\"Sentence:\", decoded)\n",
        "print(\"Predicted Review:\", label)\n",
        "print(\"Expected Value:\", \"Positive\" if y_test[arr_ind]==1 else \"Negative\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBz7OVc_bwdC",
        "outputId": "6646baf5-2f64-4c39-e33b-05408e686a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - accuracy: 0.5582 - loss: 0.6729 - val_accuracy: 0.6981 - val_loss: 0.5698\n",
            "Epoch 2/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.7648 - loss: 0.4992 - val_accuracy: 0.7730 - val_loss: 0.4914\n",
            "Epoch 3/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 28ms/step - accuracy: 0.7788 - loss: 0.4676 - val_accuracy: 0.7876 - val_loss: 0.4680\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
            "Sentence: but during some of the more # scenes there were too many close ups or dark lighting which made it hard to understand what you are seeing also on show are some nice moments of blood and gore but not # grand or # from most other films br br # odd film with # images that look like something out of a painting but still it isn't particularly # watch out it might put you in a deep #\n",
            "Predicted Review: Negative\n",
            "Expected Value: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq6HB8lgYpxB",
        "outputId": "9b07541f-172f-42ba-82af-c37724140310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 103ms/step - accuracy: 0.7368 - loss: 0.5112 - val_accuracy: 0.8304 - val_loss: 0.3827\n",
            "Epoch 2/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 105ms/step - accuracy: 0.8697 - loss: 0.3103 - val_accuracy: 0.8338 - val_loss: 0.3716\n",
            "Epoch 3/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 106ms/step - accuracy: 0.9034 - loss: 0.2444 - val_accuracy: 0.8367 - val_loss: 0.3930\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step\n"
          ]
        }
      ],
      "source": [
        "#lstm code\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)\n",
        "x_train = pad_sequences(x_train, maxlen=80)\n",
        "x_test  = pad_sequences(x_test, maxlen=80)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=80))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=32)\n",
        "\n",
        "\n",
        "pred = (model.predict(x_test) > 0.5).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm add on\n",
        "from random import randint\n",
        "arr_ind = randint(0, len(x_test)-1)\n",
        "\n",
        "\n",
        "index = imdb.get_word_index()\n",
        "reverse_index = {value: key for key, value in index.items()}\n",
        "decoded = \" \".join([reverse_index.get(i - 3, \"#\") for i in x_test[arr_ind]])\n",
        "\n",
        "\n",
        "label = \"Positive\" if pred[arr_ind][0] == 1 else \"Negative\"\n",
        "\n",
        "print(\"Sentence:\", decoded)\n",
        "print(\"Predicted Review:\", label)\n",
        "print(\"Expected Value:\", \"Positive\" if y_test[arr_ind]==1 else \"Negative\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQ1Mp0BauUQ",
        "outputId": "57bfee68-fcca-4a5f-d220-424f1ab7b4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Sentence: # # # # # # # # # # # # # # # # # # # # # # # # # # i thought this movie was brilliant it was so funny and so true too a great idea for a movie five groups of friends on their way to i've got to say that matt # as # was probably my favourite character i wish i could give this movie more than a 10 rating\n",
            "Predicted Review: Positive\n",
            "Expected Value: Positive\n"
          ]
        }
      ]
    }
  ]
}